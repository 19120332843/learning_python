{"cells":[{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"cuda:0\nNet(\n  (conv1): Conv2d(10, 6, kernel_size=(1, 4), stride=(1, 1))\n  (conv2): Conv2d(6, 10, kernel_size=(1, 3), stride=(1, 2))\n  (fc1): Linear(in_features=580, out_features=4, bias=True)\n)\nloss = 1.4061411619186401\nEpoch[1], loss: 1.47175645\nEpoch[2], loss: 1.44086578\nEpoch[3], loss: 1.43391258\nEpoch[4], loss: 1.43029694\nEpoch[5], loss: 1.42067070\nEpoch[6], loss: 1.37088910\nEpoch[7], loss: 1.43833451\nEpoch[8], loss: 1.34900742\nEpoch[9], loss: 1.26111224\nEpoch[10], loss: 1.39162732\nEpoch[11], loss: 1.10980462\nEpoch[12], loss: 1.54734801\nEpoch[13], loss: 1.44462746\nEpoch[14], loss: 1.42625127\nEpoch[15], loss: 1.40112419\nEpoch[16], loss: 1.39525791\nEpoch[17], loss: 1.34063844\nEpoch[18], loss: 1.35687782\nEpoch[19], loss: 1.37079524\nEpoch[20], loss: 1.32470724\nEpoch[21], loss: 1.28653277\nEpoch[22], loss: 1.40609076\nEpoch[23], loss: 1.17873194\nEpoch[24], loss: 1.45475189\nEpoch[25], loss: 1.46144852\nEpoch[26], loss: 1.44750878\nEpoch[27], loss: 1.43766237\nEpoch[28], loss: 1.41407024\nEpoch[29], loss: 1.39685849\nEpoch[30], loss: 1.27244504\nEpoch[31], loss: 1.23059163\nEpoch[32], loss: 1.31522649\nEpoch[33], loss: 1.13029196\nEpoch[34], loss: 0.95523500\nEpoch[35], loss: 1.16079060\nEpoch[36], loss: 0.78057252\nEpoch[37], loss: 0.99084463\nEpoch[38], loss: 0.75901536\nEpoch[39], loss: 0.90573740\nEpoch[40], loss: 0.71339175\nEpoch[41], loss: 0.74017247\nEpoch[42], loss: 0.66023795\nEpoch[43], loss: 0.69076667\nEpoch[44], loss: 0.60680614\nEpoch[45], loss: 0.64736430\nEpoch[46], loss: 0.57567869\nEpoch[47], loss: 0.59986698\nEpoch[48], loss: 0.54631038\nEpoch[49], loss: 0.55653140\nEpoch[50], loss: 0.52297311\nEpoch[51], loss: 0.51117043\nEpoch[52], loss: 0.50106847\nEpoch[53], loss: 0.48229840\nEpoch[54], loss: 0.47337446\nEpoch[55], loss: 0.46189489\nEpoch[56], loss: 0.44989904\nEpoch[57], loss: 0.44131202\nEpoch[58], loss: 0.42814680\nEpoch[59], loss: 0.42009725\nEpoch[60], loss: 0.41234698\nEpoch[61], loss: 0.39943192\nEpoch[62], loss: 0.39558055\nEpoch[63], loss: 0.38304554\nEpoch[64], loss: 0.37224720\nEpoch[65], loss: 0.36231355\nEpoch[66], loss: 0.35212248\nEpoch[67], loss: 0.34239749\nEpoch[68], loss: 0.32968842\nEpoch[69], loss: 0.31921856\nEpoch[70], loss: 0.31242161\nEpoch[71], loss: 0.30226100\nEpoch[72], loss: 0.29493627\nEpoch[73], loss: 0.20111065\nEpoch[74], loss: 0.18974419\nEpoch[75], loss: 0.18518887\nEpoch[76], loss: 0.18242370\nEpoch[77], loss: 0.18032552\nEpoch[78], loss: 0.17863496\nEpoch[79], loss: 0.17719897\nEpoch[80], loss: 0.17594330\nEpoch[81], loss: 0.17480221\nEpoch[82], loss: 0.17377907\nEpoch[83], loss: 0.17280936\nEpoch[84], loss: 0.17190931\nEpoch[85], loss: 0.17108372\nEpoch[86], loss: 0.17029101\nEpoch[87], loss: 0.16954879\nEpoch[88], loss: 0.16884872\nEpoch[89], loss: 0.16816791\nEpoch[90], loss: 0.16751553\nEpoch[91], loss: 0.16690070\nEpoch[92], loss: 0.16630445\nEpoch[93], loss: 0.16572987\nEpoch[94], loss: 0.16517040\nEpoch[95], loss: 0.16464036\nEpoch[96], loss: 0.16411354\nEpoch[97], loss: 0.16360034\nEpoch[98], loss: 0.16310070\nEpoch[99], loss: 0.16261631\nEpoch[100], loss: 0.16215785\nEpoch[101], loss: 0.16168509\nEpoch[102], loss: 0.16122691\nEpoch[103], loss: 0.16078174\nEpoch[104], loss: 0.16033143\nEpoch[105], loss: 0.15989729\nEpoch[106], loss: 0.15944492\nEpoch[107], loss: 0.15899967\nEpoch[108], loss: 0.15856432\nEpoch[109], loss: 0.15813018\nEpoch[110], loss: 0.15770768\nEpoch[111], loss: 0.15727900\nEpoch[112], loss: 0.15684140\nEpoch[113], loss: 0.15640550\nEpoch[114], loss: 0.15597017\nEpoch[115], loss: 0.15552289\nEpoch[116], loss: 0.15509169\nEpoch[117], loss: 0.15465731\nEpoch[118], loss: 0.15422640\nEpoch[119], loss: 0.15380684\nEpoch[120], loss: 0.15338394\nEpoch[121], loss: 0.15295358\nEpoch[122], loss: 0.15252683\nEpoch[123], loss: 0.15209926\nEpoch[124], loss: 0.15165946\nEpoch[125], loss: 0.15121151\nEpoch[126], loss: 0.15075892\nEpoch[127], loss: 0.15035738\nEpoch[128], loss: 0.14993378\nEpoch[129], loss: 0.14950968\nEpoch[130], loss: 0.14907727\nEpoch[131], loss: 0.14864945\nEpoch[132], loss: 0.14822114\nEpoch[133], loss: 0.14782129\nEpoch[134], loss: 0.14737836\nEpoch[135], loss: 0.14699416\nEpoch[136], loss: 0.14658376\nEpoch[137], loss: 0.14617339\nEpoch[138], loss: 0.14577056\nEpoch[139], loss: 0.14537838\nEpoch[140], loss: 0.14498097\nEpoch[141], loss: 0.14460129\nEpoch[142], loss: 0.14420670\nEpoch[143], loss: 0.14381318\nEpoch[144], loss: 0.14342520\nEpoch[145], loss: 0.14303616\nEpoch[146], loss: 0.14265472\nEpoch[147], loss: 0.14226953\nEpoch[148], loss: 0.14189106\nEpoch[149], loss: 0.14150997\nEpoch[150], loss: 0.14112680\nEpoch[151], loss: 0.14074887\nEpoch[152], loss: 0.14036355\nEpoch[153], loss: 0.13997213\nEpoch[154], loss: 0.13958658\nEpoch[155], loss: 0.13919828\nEpoch[156], loss: 0.13880596\nEpoch[157], loss: 0.13839062\nEpoch[158], loss: 0.13797850\nEpoch[159], loss: 0.13757660\nEpoch[160], loss: 0.13717651\npredicted_test:tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0,\n        0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 3, 2, 3, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n        3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n        3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0'), total:202, accuracy:0.9405940594059405, sum:190\n"}],"source":["import pandas as pd\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch.nn.init as init\n","from torch.autograd import Variable\n","import os \n","\n","\n","def Normlize(Z):\n","    Zmax, Zmin = Z.max(axis=1), Z.min(axis=1)\n","    Zmean = Z.mean(axis=1)\n","    #按列排序\n","    Zmax, Zmin = Zmax.reshape(-1, 1), Zmin.reshape(-1, 1)\n","    Zmean = Zmean.reshape(-1, 1)\n","    Z = (Z - Zmean) / (Zmax - Zmin)\n","    return Z\n","\n","\n","def Data_Reading(Normalization=True):\n","    train_x = np.load('F:\\\\gitworkspace\\\\python\\\\e-nose-cnn\\\\train\\\\trainset.npy')\n","    train_y = np.load('F:\\\\gitworkspace\\\\python\\\\e-nose-cnn\\\\train\\\\trainlabel.npy')\n","    test_x = np.load('F:\\\\gitworkspace\\\\python\\\\e-nose-cnn\\\\test\\\\testset.npy')\n","    test_y = np.load('F:\\\\gitworkspace\\\\python\\\\e-nose-cnn\\\\test\\\\testlabel.npy')\n","\n","    # Normalization\n","    train_x_Normed = Normlize(train_x)\n","    test_x_Normed = Normlize(test_x)\n","\n","    # xlsx to tensor\n","    if Normalization:\n","        train_x = torch.from_numpy(train_x_Normed).type(torch.cuda.FloatTensor)\n","        test_x = torch.from_numpy(test_x_Normed).type(torch.cuda.FloatTensor)\n","        train_y = torch.from_numpy(train_y).type(torch.int64)\n","        test_y = torch.from_numpy(test_y).type(torch.int64)\n","\n","    else:\n","        train_x = torch.from_numpy(train_x).type(torch.FloatTensor)\n","        test_x = torch.from_numpy(test_x).type(torch.FloatTensor)\n","        train_y = torch.from_numpy(train_y).type(torch.int64)\n","        test_y = torch.from_numpy(test_y).type(torch.int64)\n","    # reshape\n","    train_x = train_x.view(408, 10, 1, 120)\n","    test_x = test_x.view(202, 10, 1, 120)\n","\n","    return train_x, test_x, train_y, test_y\n","\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(10,6,(1,4),stride=(1,1))#(10 - 10)/1 + 1 = 1   (120 - 4)/1 + 1 = 117 \n","        self.conv2 = nn.Conv2d(6,10,(1,3),stride=(1,2))#(1 - 1)/1 + 1 = 1   (117 - 3)/2 + 1 = 58 116/2= 58\n","        # self.conv3 = nn.Conv2d(6,10,(1,2),stride=(1,1))\n","        self.fc1 = nn.Linear(10*1*58,4)\n","\n","       \n","        # self.conv1 = nn.Conv2d(1,6,(10,4),stride=(1,2))#59\n","        # self.conv2 = nn.Conv2d(6,10,(1,3),stride=(1,1))#57      \n","        # self.fc1 = nn.Linear(10*1*57,4)\n","\n","        # self.fc2 = nn.Linear(342,4)\n","        # self.fc3 = nn.Linear(85,4)\n","        # self.fc4 = nn.Linear(64,4)\n","        \n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                init.xavier_uniform_(m.weight)\n","                init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                init.normal_(m.weight, std=0.01)\n","    \n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.conv2(x))\n","        # x = F.relu(self.conv3(x))\n","        x = x.view(x.size(0), -1)\n","        # x = F.logsigmoid(self.fc1(x))\n","        # x = F.logsigmoid(self.fc2(x))\n","        # x = F.relu(self.fc3(x))\n","        x = self.fc1(x)\n","        # return x\n","        return x#F.softmax(x,dim=0)\n","\n","\n","if __name__ == '__main__':\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")#cuda:0\n","\n","    print(device)\n","\n","    cnn = Net()\n","    print(cnn)\n","    cnn.to(device)\n","\n","    #sgd -> stochastic gradient descent\n","    optimizer = optim.SGD(cnn.parameters(), lr=0.01, momentum=0.8)\n","    loss_func = nn.CrossEntropyLoss()\n","\n","    train_x, test_x, train_y, test_y = Data_Reading(Normalization=1)\n","    train_y = train_y.squeeze()\n","    test_y = test_y.squeeze()\n","    train_x = train_x.to(device)\n","    test_x = test_x.to(device)\n","    train_y = train_y.to(device)\n","    test_y = test_y.to(device)\n","\n","    \n","\n","    #test\n","    batch_size = 17\n","    step = 10\n","    for epoch in range(160):\n","        running_loss = 0.0\n","        for i in range(0,(int)(len(train_x)/batch_size)):\n","            t_x = Variable(train_x[i*batch_size:i*batch_size+batch_size])\n","            t_y = Variable(train_y[i*batch_size:i*batch_size+batch_size])\n","            out = cnn(t_x)\n","            #forward\n","            loss = loss_func(out, t_y)\n","            #梯度初始化为零\n","            optimizer.zero_grad()\n","             \n","            #backward\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","            if (epoch == 0):\n","                if(i == 0):\n","                    print('loss = {}'.format(loss.item()))\n","\n","            # predicted1 = torch.max(out1.data, 1)[1]\n","   \n","        running_loss = running_loss / 24\n","\n","        if (running_loss < 0.3) :\n","            optimizer = optim.SGD(cnn.parameters(), lr=0.001, momentum=0.6)\n","        elif (running_loss < 0.2) :\n","            optimizer = optim.SGD(cnn.parameters(), lr=0.0001, momentum=0.4)\n","\n","        # if (epoch + 1) % step == 0:\n","        print('Epoch[{}], loss: {:.8f}'.format(epoch + 1, running_loss))\n","    \n","    #class\n","    sum = 0\n","\n","    te_x = Variable(test_x)\n","    te_y = Variable(test_y)\n","    out1 = cnn(te_x)\n","    predicted_test = torch.max(out1.data, 1)[1]#.data.squeeze()\n","    total = te_y.size(0)\n","\n","    for j in range(te_y.size(0)):\n","        if predicted_test[j] == te_y[j]:\n","            sum += 1\n","\n","    print('predicted_test:{}, total:{}, accuracy:{}, sum:{}'.format(predicted_test, total, sum / total, sum))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}