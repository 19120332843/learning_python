{"cells":[{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"cuda:0\nNet(\n  (conv1): Conv2d(10, 13, kernel_size=(1, 4), stride=(1, 1))\n  (conv2): Conv2d(13, 17, kernel_size=(1, 3), stride=(1, 2))\n  (fc1): Linear(in_features=986, out_features=4, bias=True)\n)\nEpoch[1], loss: 1.42395754\nEpoch[2], loss: 1.40746846\nEpoch[3], loss: 1.39854743\nEpoch[4], loss: 1.39085266\nEpoch[5], loss: 1.38392742\nEpoch[6], loss: 1.37751262\nEpoch[7], loss: 1.37147075\nEpoch[8], loss: 1.36569543\nEpoch[9], loss: 1.36008952\nEpoch[10], loss: 1.35455114\nEpoch[11], loss: 1.34898737\nEpoch[12], loss: 1.34333375\nEpoch[13], loss: 1.33751504\nEpoch[14], loss: 1.33145323\nEpoch[15], loss: 1.32510429\nEpoch[16], loss: 1.31840880\nEpoch[17], loss: 1.31125174\nEpoch[18], loss: 1.30362609\nEpoch[19], loss: 1.29551540\nEpoch[20], loss: 1.28683661\nEpoch[21], loss: 1.27761894\nEpoch[22], loss: 1.26774704\nEpoch[23], loss: 1.25728142\nEpoch[24], loss: 1.24621263\nEpoch[25], loss: 1.23449783\nEpoch[26], loss: 1.22199872\nEpoch[27], loss: 1.20876779\nEpoch[28], loss: 1.19493573\nEpoch[29], loss: 1.18030500\nEpoch[30], loss: 1.16494169\nEpoch[31], loss: 1.14896969\nEpoch[32], loss: 1.13211115\nEpoch[33], loss: 1.11452679\nEpoch[34], loss: 1.09614616\nEpoch[35], loss: 1.07708586\nEpoch[36], loss: 1.05743496\nEpoch[37], loss: 1.03730432\nEpoch[38], loss: 1.01676594\nEpoch[39], loss: 0.99584416\nEpoch[40], loss: 0.97482921\nEpoch[41], loss: 0.95392631\nEpoch[42], loss: 0.93306050\nEpoch[43], loss: 0.91223968\nEpoch[44], loss: 0.89155261\nEpoch[45], loss: 0.87080649\nEpoch[46], loss: 0.85026806\nEpoch[47], loss: 0.82996850\nEpoch[48], loss: 0.81026203\nEpoch[49], loss: 0.79043472\nEpoch[50], loss: 0.77100843\nEpoch[51], loss: 0.75207543\nEpoch[52], loss: 0.73379878\nEpoch[53], loss: 0.71587745\nEpoch[54], loss: 0.69874598\nEpoch[55], loss: 0.68206992\nEpoch[56], loss: 0.66565193\nEpoch[57], loss: 0.64956995\nEpoch[58], loss: 0.63468279\nEpoch[59], loss: 0.61969500\nEpoch[60], loss: 0.60582752\nEpoch[61], loss: 0.59196210\nEpoch[62], loss: 0.57889102\nEpoch[63], loss: 0.56600782\nEpoch[64], loss: 0.55379166\nEpoch[65], loss: 0.54194730\nEpoch[66], loss: 0.52996919\nEpoch[67], loss: 0.51855247\nEpoch[68], loss: 0.50717978\nEpoch[69], loss: 0.49631382\nEpoch[70], loss: 0.48570972\nEpoch[71], loss: 0.47543494\nEpoch[72], loss: 0.46532181\nEpoch[73], loss: 0.45520951\nEpoch[74], loss: 0.44547498\nEpoch[75], loss: 0.43587992\nEpoch[76], loss: 0.42655379\nEpoch[77], loss: 0.41731729\nEpoch[78], loss: 0.40803733\nEpoch[79], loss: 0.39890197\nEpoch[80], loss: 0.38982345\nEpoch[81], loss: 0.38086117\nEpoch[82], loss: 0.37193161\nEpoch[83], loss: 0.36329198\nEpoch[84], loss: 0.35489846\nEpoch[85], loss: 0.34639482\nEpoch[86], loss: 0.33781668\nEpoch[87], loss: 0.32972042\nEpoch[88], loss: 0.32165268\nEpoch[89], loss: 0.31380580\nEpoch[90], loss: 0.30596656\nEpoch[91], loss: 0.29824094\nEpoch[92], loss: 0.23114441\nEpoch[93], loss: 0.22039189\nEpoch[94], loss: 0.21231566\nEpoch[95], loss: 0.20625667\nEpoch[96], loss: 0.20165995\nEpoch[97], loss: 0.19814406\nEpoch[98], loss: 0.19543308\nEpoch[99], loss: 0.19330639\nEpoch[100], loss: 0.19162610\nEpoch[101], loss: 0.19026752\nEpoch[102], loss: 0.18915908\nEpoch[103], loss: 0.18824066\nEpoch[104], loss: 0.18746199\nEpoch[105], loss: 0.18678117\nEpoch[106], loss: 0.18618186\nEpoch[107], loss: 0.18564809\nEpoch[108], loss: 0.18516561\nEpoch[109], loss: 0.18472084\nEpoch[110], loss: 0.18430785\nEpoch[111], loss: 0.18391844\nEpoch[112], loss: 0.18354601\nEpoch[113], loss: 0.18318670\nEpoch[114], loss: 0.18284255\nEpoch[115], loss: 0.18250670\nEpoch[116], loss: 0.18217934\nEpoch[117], loss: 0.18185889\nEpoch[118], loss: 0.18154312\nEpoch[119], loss: 0.18122156\nEpoch[120], loss: 0.18091278\nEpoch[121], loss: 0.18060975\nEpoch[122], loss: 0.18031065\nEpoch[123], loss: 0.18001111\nEpoch[124], loss: 0.17971387\nEpoch[125], loss: 0.17942232\nEpoch[126], loss: 0.17913076\nEpoch[127], loss: 0.17884130\nEpoch[128], loss: 0.17855791\nEpoch[129], loss: 0.17827320\nEpoch[130], loss: 0.17799102\nEpoch[131], loss: 0.17771448\nEpoch[132], loss: 0.17743401\nEpoch[133], loss: 0.17715772\nEpoch[134], loss: 0.17688473\nEpoch[135], loss: 0.17660970\nEpoch[136], loss: 0.17633477\nEpoch[137], loss: 0.17606094\nEpoch[138], loss: 0.17578957\nEpoch[139], loss: 0.17551985\nEpoch[140], loss: 0.17525017\nEpoch[141], loss: 0.17498069\nEpoch[142], loss: 0.17471249\nEpoch[143], loss: 0.17444453\nEpoch[144], loss: 0.17417778\nEpoch[145], loss: 0.17391327\nEpoch[146], loss: 0.17364761\nEpoch[147], loss: 0.17338346\nEpoch[148], loss: 0.17312066\nEpoch[149], loss: 0.17286023\nEpoch[150], loss: 0.17259996\nEpoch[151], loss: 0.17234300\nEpoch[152], loss: 0.17208491\nEpoch[153], loss: 0.17182844\nEpoch[154], loss: 0.17157250\nEpoch[155], loss: 0.17131725\nEpoch[156], loss: 0.17106190\nEpoch[157], loss: 0.17080739\nEpoch[158], loss: 0.17055367\nEpoch[159], loss: 0.17030079\nEpoch[160], loss: 0.17004885\nEpoch[161], loss: 0.16979844\nEpoch[162], loss: 0.16954820\nEpoch[163], loss: 0.16929874\nEpoch[164], loss: 0.16905263\nEpoch[165], loss: 0.16880576\nEpoch[166], loss: 0.16856016\nEpoch[167], loss: 0.16831878\nEpoch[168], loss: 0.16807446\nEpoch[169], loss: 0.16782979\nEpoch[170], loss: 0.16758678\nEpoch[171], loss: 0.16734498\nEpoch[172], loss: 0.16710322\nEpoch[173], loss: 0.16686359\nEpoch[174], loss: 0.16662464\nEpoch[175], loss: 0.16638532\nEpoch[176], loss: 0.16614642\nEpoch[177], loss: 0.16590825\nEpoch[178], loss: 0.16567083\nEpoch[179], loss: 0.16543431\nEpoch[180], loss: 0.16519867\nEpoch[181], loss: 0.16496355\nEpoch[182], loss: 0.16473007\nEpoch[183], loss: 0.16449760\nEpoch[184], loss: 0.16426469\nEpoch[185], loss: 0.16403187\nEpoch[186], loss: 0.16379878\nEpoch[187], loss: 0.16356672\nEpoch[188], loss: 0.16333530\nEpoch[189], loss: 0.16310469\nEpoch[190], loss: 0.16287461\nEpoch[191], loss: 0.16264637\nEpoch[192], loss: 0.16241956\nEpoch[193], loss: 0.16219307\nEpoch[194], loss: 0.16196611\nEpoch[195], loss: 0.16174046\nEpoch[196], loss: 0.16151462\nEpoch[197], loss: 0.16128980\nEpoch[198], loss: 0.16106488\nEpoch[199], loss: 0.16084026\nEpoch[200], loss: 0.16061695\npredicted_test:tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n        3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0'), total:202, accuracy:0.9603960396039604, sum:194\n"}],"source":["import pandas as pd\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch.nn.init as init\n","from torch.autograd import Variable\n","import os \n","\n","\n","def Normlize(Z):\n","    Zmax, Zmin = Z.max(axis=1), Z.min(axis=1)\n","    Zmean = Z.mean(axis=1)\n","    #按列排序\n","    Zmax, Zmin = Zmax.reshape(-1, 1), Zmin.reshape(-1, 1)\n","    Zmean = Zmean.reshape(-1, 1)\n","    Z = (Z - Zmean) / (Zmax - Zmin)\n","    return Z\n","\n","\n","def Data_Reading(Normalization=True):\n","    train_x = np.load('F:\\\\gitworkspace\\\\python\\\\e-nose-cnn\\\\train\\\\trainset.npy')\n","    train_y = np.load('F:\\\\gitworkspace\\\\python\\\\e-nose-cnn\\\\train\\\\trainlabel.npy')\n","    test_x = np.load('F:\\\\gitworkspace\\\\python\\\\e-nose-cnn\\\\test\\\\testset.npy')\n","    test_y = np.load('F:\\\\gitworkspace\\\\python\\\\e-nose-cnn\\\\test\\\\testlabel.npy')\n","\n","    # Normalization\n","    train_x_Normed = Normlize(train_x)\n","    test_x_Normed = Normlize(test_x)\n","\n","    # xlsx to tensor\n","    if Normalization:\n","        train_x = torch.from_numpy(train_x_Normed).type(torch.cuda.FloatTensor)\n","        test_x = torch.from_numpy(test_x_Normed).type(torch.cuda.FloatTensor)\n","        train_y = torch.from_numpy(train_y).type(torch.int64)\n","        test_y = torch.from_numpy(test_y).type(torch.int64)\n","\n","    else:\n","        train_x = torch.from_numpy(train_x).type(torch.FloatTensor)\n","        test_x = torch.from_numpy(test_x).type(torch.FloatTensor)\n","        train_y = torch.from_numpy(train_y).type(torch.int64)\n","        test_y = torch.from_numpy(test_y).type(torch.int64)\n","    # reshape\n","    train_x = train_x.view(408, 10, 1, 120)\n","    test_x = test_x.view(202, 10, 1, 120)\n","\n","    return train_x, test_x, train_y, test_y\n","\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(10,13,(1,4),stride=(1,1))#(10 - 10)/1 + 1 = 1   (120 - 4)/1 + 1 = 117 \n","        self.conv2 = nn.Conv2d(13,17,(1,3),stride=(1,2))#(1 - 1)/1 + 1 = 1   (117 - 3)/2 + 1 = 58 116/2= 58\n","        self.fc1 = nn.Linear(17*1*58,4)\n","\n","       \n","        # self.conv1 = nn.Conv2d(1,6,(10,4),stride=(1,2))#59\n","        # self.conv2 = nn.Conv2d(6,10,(1,3),stride=(1,1))#57      \n","        # self.fc1 = nn.Linear(10*1*57,4)\n","\n","        # self.fc2 = nn.Linear(342,4)\n","        # self.fc3 = nn.Linear(85,4)\n","        # self.fc4 = nn.Linear(64,4)\n","        \n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                init.xavier_uniform_(m.weight)\n","                init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                init.normal_(m.weight, std=0.01)\n","    \n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.conv2(x))\n","        # x = F.lrelu(self.conv3(x))\n","        x = x.view(x.size(0), -1)\n","        # x = F.logsigmoid(self.fc1(x))\n","        # x = F.logsigmoid(self.fc2(x))\n","        # x = F.relu(self.fc3(x))\n","        x = self.fc1(x)\n","        # return x\n","        return x#F.softmax(x,dim=0)\n","\n","\n","if __name__ == '__main__':\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")#cuda:0\n","\n","    print(device)\n","\n","    cnn = Net()\n","    print(cnn)\n","    cnn.to(device)\n","\n","    #sgd -> stochastic gradient descent\n","    optimizer = optim.SGD(cnn.parameters(), lr=0.001, momentum=0.8)\n","    loss_func = nn.CrossEntropyLoss()\n","\n","    train_x, test_x, train_y, test_y = Data_Reading(Normalization=1)\n","    train_y = train_y.squeeze()\n","    test_y = test_y.squeeze()\n","    train_x = train_x.to(device)\n","    test_x = test_x.to(device)\n","    train_y = train_y.to(device)\n","    test_y = test_y.to(device)\n","\n","    \n","\n","    #test\n","    batch_size = 17\n","    step = 10\n","    for epoch in range(200):\n","        running_loss = 0.0\n","        for i in range(0,(int)(len(train_x)/batch_size)):\n","            t_x = Variable(train_x[i*batch_size:i*batch_size+batch_size])\n","            t_y = Variable(train_y[i*batch_size:i*batch_size+batch_size])\n","            out = cnn(t_x)\n","            #forward\n","            loss = loss_func(out, t_y)\n","            #梯度初始化为零\n","            optimizer.zero_grad()\n","             \n","            #backward\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","            predicted1 = torch.max(out1.data, 1)[1]\n","   \n","        running_loss = running_loss / 24\n","\n","        if (running_loss < 0.3) :\n","            optimizer = optim.SGD(cnn.parameters(), lr=0.0001, momentum=0.6)\n","        elif (running_loss < 0.2) :\n","            optimizer = optim.SGD(cnn.parameters(), lr=0.00001, momentum=0.4)\n","\n","        # if (epoch + 1) % step == 0:\n","        print('Epoch[{}], loss: {:.8f}'.format(epoch + 1, running_loss))\n","    \n","    #class\n","    sum = 0\n","\n","    te_x = Variable(test_x)\n","    te_y = Variable(test_y)\n","    out1 = cnn(te_x)\n","    predicted_test = torch.max(out1.data, 1)[1]#.data.squeeze()\n","    total = te_y.size(0)\n","\n","    for j in range(te_y.size(0)):\n","        if predicted_test[j] == te_y[j]:\n","            sum += 1\n","\n","    print('predicted_test:{}, total:{}, accuracy:{}, sum:{}'.format(predicted_test, total, sum / total, sum))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}