# e-nose cnn

把以下四种数据放入pop-cnn，测试分类效果。

binglang-槟榔

gaoliangjiang-高良姜

sharen-砂仁

zhike-枳壳

## draw_test

画图测试

## nos-data

原始数据，其中，每个文件夹的1是训练集，2是测试集

## train

训练集

## test

测试集

## 数据整理流程

1. 把每个nos转为csv,一定要加header；

2. 把每个csv转置并合成一个csv，一定要加header；

## pop-cnn

在原来的基础上，改成分类

1. 先把csv转成numpy想要的格式npy；

## 2019.10.29

之前的实验不理想，现在重新设计实验。

实验原则：

1. 把同一个标号的数据求均值，做一个样本；(弃用此方案，我是做分类，不是做回归，由于电子鼻采集时需要吸气，我们可以认为同一个物体连续采集多次，是浓度不同)

|名字|数据|
|:-:|:-:|
|槟榔|18+15+15=48|
|高良姜|20|
|砂仁|31|
|枳壳|100+|
|莪术|27|
|干姜|25+25+25+25=100|
|牡丹皮|8+27+27+27+27=116|

### 解决问题

分类类别不确定，每类样本数量不确定的分类问题。

### 首先进行数据处理

1. 以实验原则为底线，处理数据；

2. 在代码中加入新的想法。

### 参考论文

Cost-sensitive learning of deep feature representations from imbalanced data.

## 2019.11.1

现在确定一下工作方向

* 首先数据从原始数据中找出来，每类找一百个。如果数量少的，如高良姜等，则找一个文件夹中的1234个。其他超过的，就只要第一个。

### 数据处理

1. nos转csv

2. csv转图像，找出每个csv前面还没起来的，裁剪前面的。然后裁剪后面的，只要10*100的数据,我觉得可以先试一下没有裁剪的(不做)

### 训练

1. 先用cnn

2. 然后看别人fpga做cnn的论文和代码，再决定是否使用cnn+svm

3. 算法可以使用的方向是：预测精度达到90以上，预处理算法可以接受进来一个数据处理一个，不需要整体处理
