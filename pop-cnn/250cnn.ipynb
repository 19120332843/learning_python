{"cells":[{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"import pandas as pd\nimport torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.nn.init as init\nfrom torch.autograd import Variable\n\n\ndef Normlize(Z):\n    Zmax, Zmin = Z.max(axis=1), Z.min(axis=1)\n    Zmean = Z.mean(axis=1)\n    #按列排序\n    Zmax, Zmin = Zmax.reshape(-1, 1), Zmin.reshape(-1, 1)\n    Zmean = Zmean.reshape(-1, 1)\n    Z = (Z - Zmean) / (Zmax - Zmin)\n    return Z\n\ndef Data_Reading(Normalization=True):\n    # Read the xlsx\n    '''\n    //读取excel的值\n    train_x = pd.read_excel( \"trainingset.xlsx\", 'Input',header = None)\n    test_x = pd.read_excel(\"oilsset.xlsx\",'oils',header = None)\n    test_z = pd.read_excel(\"newodorset.xlsx\",'new',header = None)\n    train_y = pd.read_excel(\"trainingy.xlsx\",'Output',header = None)\n    testy1 = pd.read_excel(\"oilsy.xlsx\",'oy',header = None)\n    testy2 = pd.read_excel(\"newy.xlsx\",'ny',header = None)\n    \n    //使用前一个观察值填充 \n    train_x = train_x.fillna(method='ffill')\n    test_x = test_x.fillna(method='ffill')\n    text_z = test_z.fillna(method='ffill')\n    train_y = train_y.fillna(method='ffill')\n\n    np.save('trainingset.npy', train_x)\n    np.save('oilsset.npy',test_x)\n    np.save('newodorset.npy', test_z)\n    np.save('trainingy.npy', train_y)\n    np.save('testy1.npy', testy1)\n    np.save('testy2.npy', testy2)\n    '''\n    train_x = np.load('F:\\\\gitworkspace\\\\python\\\\pop-cnn\\\\trainingset.npy')\n    test_x = np.load('F:\\\\gitworkspace\\\\python\\\\pop-cnn\\\\oilsset.npy')\n    test_z = np.load('F:\\\\gitworkspace\\\\python\\\\pop-cnn\\\\newodorset.npy')\n    train_y = np.load('F:\\\\gitworkspace\\\\python\\\\pop-cnn\\\\trainingy.npy')\n    testy1 = np.load(\"F:\\\\gitworkspace\\\\python\\\\pop-cnn\\\\testy1.npy\")\n    testy2 = np.load(\"F:\\\\gitworkspace\\\\python\\\\pop-cnn\\\\testy2.npy\")\n \n\n    # Normalization\n    train_x_Normed = Normlize(train_x)\n    test_x_Normed = Normlize(test_x)\n    test_z_Normed = Normlize(test_z)\n    train_y = train_y / 10000\n    testy1 = testy1 / 10000\n    testy2 = testy2 / 10000\n\n    # xlsx to tensor\n    if Normalization:\n        train_x = torch.from_numpy(train_x_Normed).type(torch.cuda.FloatTensor)\n        test_x = torch.from_numpy(test_x_Normed).type(torch.cuda.FloatTensor)\n        test_z = torch.from_numpy(test_z_Normed).type(torch.cuda.FloatTensor)\n        train_y = torch.from_numpy(train_y).type(torch.cuda.FloatTensor)\n        testy1 = torch.from_numpy(testy1).type(torch.cuda.FloatTensor)\n        testy2 = torch.from_numpy(testy2).type(torch.cuda.FloatTensor)\n\n    else:\n        train_x = torch.from_numpy(train_x).type(torch.cuda.FloatTensor)\n        test_x = torch.from_numpy(test_x).type(torch.cuda.FloatTensor)\n        test_z = torch.from_numpy(test_z).type(torch.cuda.FloatTensor)\n        train_y = torch.from_numpy(train_y).type(torch.cuda.FloatTensor)\n        testy1 = torch.from_numpy(testy1).type(torch.cuda.FloatTensor)\n        testy2 = torch.from_numpy(testy2).type(torch.cuda.FloatTensor)\n\n\n    # reshape\n    train_x = train_x.view(238, 1, 16, 250)\n    test_x = test_x.view(108, 1, 16, 250)\n    test_z = test_z.view(95, 1, 16, 250)\n    return train_x, test_x, test_z, train_y,testy1,testy2\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1,6,(16,4),stride=(1,3))\n        self.conv2 = nn.Conv2d(6,10,(1,3),stride=(1,2))\n        #self.conv3 = nn.Conv2d(10,14,(1,4),stride=(1,2))\n        self.fc = nn.Linear(10*1*41,1)\n        \n\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.xavier_uniform_(m.weight)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, std=0.01)\n\n\n             \n    def forward(self, x):\n        x = F.relu(self.conv1(x))#（238,6,1,124）\n        x = F.relu(self.conv2(x))#（238,16,1,23）\n        #x = F.relu(self.conv3(x))\n        x = x.view(x.size(0), -1) # flatten the tensor\n        x = self.fc(x)\n        return x\n\n#training\nbatch_size = 14\ndef train(train_x,train_y,step=20):\n    for epoch in range(160):\n        for i in range(0,(int)(len(train_x)/batch_size)):\n            t_x = Variable(train_x[i*batch_size:i*batch_size+batch_size])\n            t_y = Variable(train_y[i*batch_size:i*batch_size+batch_size])\n            t_x = t_x.to(device)\n            t_y = t_y.to(device)\n            out = cnn(t_x)\n            #forward\n            loss = loss_func(out, t_y)\n            optimizer.zero_grad()\n            #backward\n            loss.backward()\n            optimizer.step()\n        if (epoch + 1) % step == 0:\n            print('Epoch[{}/{}], loss: {:.12f},'.format(epoch + 1,160, loss.item()))\n        \n            \n#predicting\ndef predict(test_x,testy1):\n    for epoch in range(30):\n        te_x = Variable(test_x)\n        tey1 = Variable(testy1)\n        out1 = cnn(te_x)\n        loss1 = loss_func(out1, tey1)\n        out1 = out1 * 10000\n        #print('Epoch[{}/{}], loss1: {:.12f},'.format(epoch + 1, 30, loss1.item()))\n        print('epoch, loss1:, out1', epoch + 1, loss1, out1)\n\ndef newodor(test_z,testy2):\n    for epoch in range(10):\n        te_z = Variable(test_z)\n        tey2 = Variable(testy2)\n        out2 = cnn(te_z)\n        loss2 = loss_func(out2, tey2)\n        out2 = out2 * 10000\n        #print('Epoch[{}/{}], loss2: {:.12f},'.format(epoch + 1, 10, loss2.item()))\n        print('epoch, loss2:, out2', epoch + 1, loss2, out2)\n\n\n\n\nif __name__ == '__main__':\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(device)\n    \n    cnn = Net()\n    print(cnn)\n    cnn.to(device)\n\n\n    optimizer = optim.SGD(cnn.parameters(), lr=0.0001, momentum=0.8)\n    loss_func = nn.MSELoss()\n\n    train_x, test_x, test_z, train_y,testy1,testy2 = Data_Reading(Normalization=True)\n    train(train_x, train_y, step=20)\n    predict(test_x,testy1)\n    newodor(test_z,testy2)\n\n"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}